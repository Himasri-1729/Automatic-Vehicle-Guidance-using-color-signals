The project "Autonomous Vehicle Guidance Using Color Signals" introduces a cost-effective and innovative solution for autonomous navigation using color detection. The system utilizes a camera to capture real-time images and detect predefined color signals using OpenCV, which are interpreted as movement commands for the vehicle. This setup significantly reduces dependency on expensive sensors, relying instead on simple, visual cues. The project successfully integrates hardware like NodeMCU ESP8266, L298N motor driver, and DC motors with software components including Python, Arduino IDE, and color detection libraries to execute vehicle movements such as stop, go, turn left/right, or reverse, based on recognized color signals.

In the implementation phase, the vehicle uses a webcam to continuously monitor its surroundings and send captured frames to the processing unit. These frames are analyzed using OpenCV to extract color features, which are classified using a K-Nearest Neighbors (KNN) algorithm trained on a dataset of common colors. Upon detecting a specific color, corresponding commands are sent via serial communication to the Arduino board, which then activates the motors accordingly. The system's behavior, such as moving forward for green or stopping for red, was rigorously tested under controlled conditions and showed reliable performance when color visibility was optimal.

Future improvements can enhance the system's robustness and versatility. One major enhancement would be the integration of a Raspberry Pi, allowing the entire image processing pipeline to run onboard, thus eliminating the need for a separate computer. Advanced machine learning techniques could be employed to make the color detection more resilient to varying lighting conditions and environmental interferences. Moreover, combining pattern recognition with color detection could allow for more complex navigation and obstacle avoidance, moving this project closer to real-world autonomous vehicle applications.
